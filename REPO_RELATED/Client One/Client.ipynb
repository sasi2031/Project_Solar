{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sasi Kanth\\anaconda3\\envs\\rengoku\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.2432 - val_loss: 0.1100\n",
      "Epoch 2/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0979 - val_loss: 0.1440\n",
      "Epoch 3/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0665 - val_loss: 0.1724\n",
      "Epoch 4/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0488 - val_loss: 0.1544\n",
      "Epoch 5/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0413 - val_loss: 0.1331\n",
      "Epoch 6/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0395 - val_loss: 0.1056\n",
      "Epoch 7/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0350 - val_loss: 0.0918\n",
      "Epoch 8/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0323 - val_loss: 0.0794\n",
      "Epoch 9/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0311 - val_loss: 0.0760\n",
      "Epoch 10/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0305 - val_loss: 0.0726\n",
      "Epoch 11/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0293 - val_loss: 0.0727\n",
      "Epoch 12/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0268 - val_loss: 0.0643\n",
      "Epoch 13/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0274 - val_loss: 0.0599\n",
      "Epoch 14/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0273 - val_loss: 0.0634\n",
      "Epoch 15/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0271 - val_loss: 0.0548\n",
      "Epoch 16/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0261 - val_loss: 0.0539\n",
      "Epoch 17/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0245 - val_loss: 0.0510\n",
      "Epoch 18/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0249 - val_loss: 0.0489\n",
      "Epoch 19/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0244 - val_loss: 0.0494\n",
      "Epoch 20/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0234 - val_loss: 0.0474\n",
      "Epoch 21/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0234 - val_loss: 0.0474\n",
      "Epoch 22/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0220 - val_loss: 0.0500\n",
      "Epoch 23/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0227 - val_loss: 0.0493\n",
      "Epoch 24/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0225 - val_loss: 0.0437\n",
      "Epoch 25/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0219 - val_loss: 0.0437\n",
      "Epoch 26/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0209 - val_loss: 0.0418\n",
      "Epoch 27/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0216 - val_loss: 0.0446\n",
      "Epoch 28/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0217 - val_loss: 0.0424\n",
      "Epoch 29/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0210 - val_loss: 0.0419\n",
      "Epoch 30/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0210 - val_loss: 0.0419\n",
      "Epoch 31/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0206 - val_loss: 0.0447\n",
      "Epoch 32/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0211 - val_loss: 0.0442\n",
      "Epoch 33/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0196 - val_loss: 0.0414\n",
      "Epoch 34/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0207 - val_loss: 0.0429\n",
      "Epoch 35/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0193 - val_loss: 0.0435\n",
      "Epoch 36/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0204 - val_loss: 0.0428\n",
      "Epoch 37/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0201 - val_loss: 0.0428\n",
      "Epoch 38/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0201 - val_loss: 0.0390\n",
      "Epoch 39/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0200 - val_loss: 0.0452\n",
      "Epoch 40/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0205 - val_loss: 0.0400\n",
      "Epoch 41/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0187 - val_loss: 0.0411\n",
      "Epoch 42/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0181 - val_loss: 0.0376\n",
      "Epoch 43/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0198 - val_loss: 0.0401\n",
      "Epoch 44/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0194 - val_loss: 0.0397\n",
      "Epoch 45/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0193 - val_loss: 0.0395\n",
      "Epoch 46/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0191 - val_loss: 0.0367\n",
      "Epoch 47/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0186 - val_loss: 0.0394\n",
      "Epoch 48/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0192 - val_loss: 0.0376\n",
      "Epoch 49/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0190 - val_loss: 0.0395\n",
      "Epoch 50/50\n",
      "\u001b[1m359/359\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0189 - val_loss: 0.0398\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Error: [317044.267] at timestamp: 2024-11-08T14:45:00.000000000\n",
      "Min Error: [8.56075] at timestamp: 2024-12-09T09:30:00.000000000\n",
      "Mean Absolute Error (MAE): 56744.952040782395\n",
      "Mean Squared Error (MSE): 5917029027.944354\n",
      "Mean Absolute Percentage Error (MAPE): 13.490427776022347\n",
      "Accuracy: 86.50957222397766%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-07 11:15:00</td>\n",
       "      <td>250223.000</td>\n",
       "      <td>214873.859375</td>\n",
       "      <td>35349.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-07 11:30:00</td>\n",
       "      <td>251764.600</td>\n",
       "      <td>221188.156250</td>\n",
       "      <td>30576.443750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-07 11:45:00</td>\n",
       "      <td>263703.467</td>\n",
       "      <td>229580.500000</td>\n",
       "      <td>34122.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-07 12:00:00</td>\n",
       "      <td>308338.800</td>\n",
       "      <td>234508.062500</td>\n",
       "      <td>73830.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-07 12:15:00</td>\n",
       "      <td>322848.267</td>\n",
       "      <td>243123.234375</td>\n",
       "      <td>79725.032625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp      Actual      Predicted         Error\n",
       "0 2024-12-07 11:15:00  250223.000  214873.859375  35349.140625\n",
       "1 2024-12-07 11:30:00  251764.600  221188.156250  30576.443750\n",
       "2 2024-12-07 11:45:00  263703.467  229580.500000  34122.967000\n",
       "3 2024-12-07 12:00:00  308338.800  234508.062500  73830.737500\n",
       "4 2024-12-07 12:15:00  322848.267  243123.234375  79725.032625"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Load your new dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\Sasi Kanth\\Desktop\\YayySOLARDATA\\Dataset\\Mar_merged_weather_power_data.csv\")\n",
    "\n",
    "# Drop unnecessary timestamp columns\n",
    "data.drop(columns=['timestamp_x', 'timestamp_y'], inplace=True)\n",
    "\n",
    "# Convert 'planttimestamp' to datetime\n",
    "data['planttimestamp'] = pd.to_datetime(data['planttimestamp'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaT in 'planttimestamp'\n",
    "data = data.dropna(subset=['planttimestamp'])\n",
    "data = data[(data['planttimestamp'].dt.time >= pd.to_datetime('06:30').time()) &\n",
    "            (data['planttimestamp'].dt.time <= pd.to_datetime('18:45').time())]\n",
    "\n",
    "# Define the correct feature names based on the printed column names\n",
    "features = [\n",
    "    'AXPPL 380MW ICR22 WMS 6 Wind Direction (°)',\n",
    "    'AXPPL 380MW ICR22 WMS 6 GHI (W/m²)',\n",
    "    'AXPPL 380MW ICR22 WMS 6 Ambient Temperature (°C)',\n",
    "    'AXPPL 380MW ICR22 WMS 6 Humidity (%)',\n",
    "    'AXPPL 380MW ICR22 WMS 6 POA (W/m²)',\n",
    "    'AXPPL 380MW ICR22 WMS 6 Wind Speed (m/s)',\n",
    "    'AXPPL 380MW ICR22 WMS 6 Module Temperature (°C)'\n",
    "]\n",
    "target_column = 'AXPPL 380MW MCR PQM Active Power (kW)'\n",
    "\n",
    "# Prepare feature and target datasets\n",
    "X_data = data[features]\n",
    "y_data = data[target_column]\n",
    "\n",
    "# Replace any '-' with NaN and convert the columns to numeric\n",
    "X_data = X_data.replace('-', np.nan).astype(float)\n",
    "y_data = y_data.replace('-', np.nan).astype(float)\n",
    "\n",
    "# Interpolate missing values (linear interpolation based on neighboring points)\n",
    "X_data = X_data.interpolate(method='linear', limit_direction='both')\n",
    "y_data = y_data.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "# Drop rows where interpolation was not possible (if any NaN values still exist)\n",
    "X_data = X_data.dropna()\n",
    "y_data = y_data[X_data.index]  # Keep only the indices that are valid in X_data\n",
    "\n",
    "# Feature scaling\n",
    "scaler_X = MinMaxScaler()\n",
    "scaled_X = scaler_X.fit_transform(X_data)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "scaled_y = scaler_y.fit_transform(y_data.values.reshape(-1, 1))\n",
    "\n",
    "# Create sequences and labels for LSTM\n",
    "def create_sequences(X, y, sequence_length):\n",
    "    sequences_X = []\n",
    "    sequences_y = []\n",
    "    for i in range(len(X) - sequence_length):\n",
    "        sequences_X.append(X[i:i + sequence_length])\n",
    "        sequences_y.append(y[i + sequence_length])\n",
    "    return np.array(sequences_X), np.array(sequences_y)\n",
    "\n",
    "sequence_length = 24 # Number of time steps (e.g., for 2 hours ahead)\n",
    "X, y = create_sequences(scaled_X, scaled_y, sequence_length)\n",
    "\n",
    "# Split into training and testing datasets\n",
    "split = int(0.7 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Build the LSTM model\n",
    "# Build the modified LSTM model with more layers and units\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=256, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))  # Increased units\n",
    "model.add(Dropout(0.4))  # Increased dropout to prevent overfitting\n",
    "# model.add(LSTM(units=128, return_sequences=True))\n",
    "# model.add(Dropout(0.4))\n",
    "model.add(LSTM(units=64, return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)  # Reduced learning rate\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Train the model with more epochs and smaller batch size\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_test, y_test))  # Increased epochs, decreased batch size\n",
    "\n",
    "# Predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "predictions = scaler_y.inverse_transform(predictions)\n",
    "\n",
    "# Save the model and weights\n",
    "model.save('solar_model_new.h5')\n",
    "model.save_weights('solar_model_new.weights.h5')\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Inverse transform y_test for comparison\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate errors\n",
    "mae = mean_absolute_error(y_test_inv, predictions)\n",
    "mse = mean_squared_error(y_test_inv, predictions)\n",
    "mape = mean_absolute_percentage_error(y_test_inv, predictions)\n",
    "\n",
    "# Calculate accuracy (simple method based on inverse MAPE)\n",
    "accuracy = 100 - mape\n",
    "\n",
    "# Calculate absolute errors to find max and min error timestamps\n",
    "errors = np.abs(y_test_inv - predictions)\n",
    "max_error_idx = np.argmax(errors)\n",
    "min_error_idx = np.argmin(errors)\n",
    "\n",
    "# Get timestamps for max and min error\n",
    "timestamps = data['planttimestamp'].values[-len(y_test):]\n",
    "max_error_time = timestamps[max_error_idx]\n",
    "min_error_time = timestamps[min_error_idx]\n",
    "\n",
    "# Output evaluation results\n",
    "print(f\"Max Error: {errors[max_error_idx]} at timestamp: {max_error_time}\")\n",
    "print(f\"Min Error: {errors[min_error_idx]} at timestamp: {min_error_time}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}\")\n",
    "print(f\"Accuracy: {accuracy}%\")\n",
    "\n",
    "# Optionally, save predictions and errors to a DataFrame for further analysis\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Timestamp': timestamps,\n",
    "    'Actual': y_test_inv.flatten(),\n",
    "    'Predicted': predictions.flatten(),\n",
    "    'Error': errors.flatten()\n",
    "})\n",
    "\n",
    "# Display predictions_df if you want to check it\n",
    "predictions_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({'Actual': scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten(), \n",
    "                               'Predicted': predictions.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-07 11:15:00</td>\n",
       "      <td>250223.000</td>\n",
       "      <td>240520.671875</td>\n",
       "      <td>9702.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-07 11:30:00</td>\n",
       "      <td>251764.600</td>\n",
       "      <td>231789.750000</td>\n",
       "      <td>19974.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-07 11:45:00</td>\n",
       "      <td>263703.467</td>\n",
       "      <td>240398.750000</td>\n",
       "      <td>23304.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-07 12:00:00</td>\n",
       "      <td>308338.800</td>\n",
       "      <td>234634.906250</td>\n",
       "      <td>73703.893750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-07 12:15:00</td>\n",
       "      <td>322848.267</td>\n",
       "      <td>257794.578125</td>\n",
       "      <td>65053.688875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp      Actual      Predicted         Error\n",
       "0 2024-12-07 11:15:00  250223.000  240520.671875   9702.328125\n",
       "1 2024-12-07 11:30:00  251764.600  231789.750000  19974.850000\n",
       "2 2024-12-07 11:45:00  263703.467  240398.750000  23304.717000\n",
       "3 2024-12-07 12:00:00  308338.800  234634.906250  73703.893750\n",
       "4 2024-12-07 12:15:00  322848.267  257794.578125  65053.688875"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rengoku",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
